import os
import re
import copy
import torch
os.environ["CUDA_VISIBLE_DEVICES"] = "0"
import platform
from transformers import AutoTokenizer, AutoModel
from utility.db_tools import Cur_db
from utility.loggers import logger
from sentence_transformers import util
from prompt import table_schema, embedder,corpus_embeddings, corpus,In_context_prompt

tokenizer = AutoTokenizer.from_pretrained("ChatGlm-6b", trust_remote_code=True)
model = AutoModel.from_pretrained("ChatGlm-6b", trust_remote_code=True).half().cuda()
model = model.eval() 
os_name = platform.system()


# chatbot_prompt = """
# ä½ æ˜¯ä¸€ä¸ªæ–‡æœ¬è½¬SQLçš„ç”Ÿæˆå™¨ï¼Œä½ çš„ä¸»è¦ç›®æ ‡æ˜¯å°½å¯èƒ½çš„ååŠ©ç”¨æˆ·ï¼Œå°†è¾“å…¥çš„æ–‡æœ¬è½¬æ¢ä¸ºæ­£ç¡®çš„SQLè¯­å¥ã€‚
# ä¸Šä¸‹æ–‡å¼€å§‹
# è¡¨åå’Œè¡¨å­—æ®µæ¥è‡ªä»¥ä¸‹è¡¨ï¼š
# """

query_template = """é—®: <user_input>
ç­”: 
"""


def main():
    db_con = Cur_db()
    db_con.pymysql_cur()
    print("æ¬¢è¿ä½¿ç”¨ ChatGLM-6B æ¨¡å‹ï¼Œè¾“å…¥å†…å®¹å³å¯è¿›è¡Œå¯¹è¯ï¼Œclear æ¸…ç©ºå¯¹è¯å†å²ï¼Œstop ç»ˆæ­¢ç¨‹åº")
    history = []
    while True:
        chatbot_prompt = """
ä½ æ˜¯ä¸€ä¸ªæ–‡æœ¬è½¬SQLçš„ç”Ÿæˆå™¨ï¼Œä½ çš„ä¸»è¦ç›®æ ‡æ˜¯å°½å¯èƒ½çš„ååŠ©ç”¨æˆ·å°†è¾“å…¥çš„æ–‡æœ¬è½¬æ¢ä¸ºæ­£ç¡®çš„SQLè¯­å¥ã€‚
ä¸Šä¸‹æ–‡å¼€å§‹
ç”Ÿæˆçš„è¡¨åå’Œè¡¨å­—æ®µå‡æ¥è‡ªä»¥ä¸‹è¡¨ï¼š
"""
        query = input("\nğŸ§‘ç”¨æˆ·ï¼š")
        if query == "stop":
            break
        if query == "clear":
            history = []
            command = 'cls' if os_name == 'Windows' else 'clear'
            os.system(command)
            print("æ¬¢è¿ä½¿ç”¨ ChatGLM-6B æ¨¡å‹ï¼Œè¾“å…¥å†…å®¹å³å¯è¿›è¡Œå¯¹è¯ï¼Œclear æ¸…ç©ºå¯¹è¯å†å²ï¼Œstop ç»ˆæ­¢ç¨‹åº")
            continue
        top_k = 3 
        query_embedding = embedder.encode(query, convert_to_tensor=True) # ä¸6å¼ è¡¨çš„è¡¨åå’Œè¾“å…¥çš„é—®é¢˜è¿›è¡Œç›¸ä¼¼åº¦è®¡ç®—
        cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0] 
        top_results = torch.topk(cos_scores, k=top_k) # æ‹¿åˆ°topk=3çš„è¡¨å
        # ç»„åˆPrompt
        table_nums = 0 
        for score, idx in zip(top_results[0], top_results[1]):
            # é˜ˆå€¼è¿‡æ»¤
            if score > 0.45:
                table_nums += 1
                chatbot_prompt += table_schema[corpus[idx]]
        chatbot_prompt += "ä¸Šä¸‹æ–‡ç»“æŸ\n"
        # In-Context Learning
        if table_nums >= 2 and not history: # å¦‚æœè¡¨åå¤§äºç­‰äº2ä¸ªï¼Œä¸”æ²¡æœ‰å†å²è®°å½•ï¼Œå°±åŠ ä¸ŠIn-Context Learning
            chatbot_prompt += In_context_prompt
        #  åŠ ä¸ŠæŸ¥è¯¢æ¨¡æ¿
        chatbot_prompt += query_template
        # chatbot_prompt = chatbot_prompt.replace(" ", "")
        # ç”Ÿæˆè¾“å…¥çš„prompt
        copy_query = copy.deepcopy(query)
        if history:
            query = query
        else:
            query = chatbot_prompt.replace("<user_input>", query)
        response, history = model.chat(tokenizer, query, history=history, temperature=0.1) # ç”ŸæˆSQL
        
        response = re.split("```|\n\n", response)
        print(response)
        for text in response:
            if "SELECT" in text:
                response = text
                break
        else:
            response = response[0]
        response = response.replace("\n", " ").replace("``", "").replace("`", "").strip()
        response = re.sub(' +',' ', response)
        print(f"ğŸ¤–ChatGLM-6Bï¼š{response}") 
        if "å¾ˆæŠ±æ­‰" in response:
            continue
        # ç»“æœæŸ¥è¯¢
        res = db_con.selectMany(response)
        print("result table:", res)
        # queryå’Œsqlå…¥åº“
        sql = "INSERT INTO query_sql_result (user_query, gen_sql) VALUES (%s, %s)"
        val = [copy_query, response]
        db_con.insert(sql, val)
        history = []

if __name__ == "__main__":
    main()